# app.py - ChatAcredita con RAG funcional (100% compatible con Streamlit Cloud)
import os
import streamlit as st
from openai import OpenAI
import zipfile

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INICIALIZACIÃ“N SEGURA DE SESSION STATE (PRIMERO QUE TODO)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
if "messages" not in st.session_state:
    st.session_state.messages = []
if "document_text" not in st.session_state:
    st.session_state.document_text = ""
if "document_name" not in st.session_state:
    st.session_state.document_name = ""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARGAR VECTORSTORE CHROMADB PARA RAG
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def ensure_chroma_db():
    """Descomprime chroma_db.zip si chroma_db/ no existe"""
    chroma_dir = "chroma_db"
    chroma_zip = "chroma_db.zip"
    
    if not os.path.exists(chroma_dir) and os.path.exists(chroma_zip):
        with st.spinner(f"ğŸ“¦ Descomprimiendo base de conocimiento..."):
            try:
                with zipfile.ZipFile(chroma_zip, 'r') as zip_ref:
                    zip_ref.extractall(".")
                st.sidebar.success("âœ… Base de conocimiento cargada")
                return True
            except Exception as e:
                st.sidebar.error(f"âŒ Error descomprimiendo: {str(e)[:100]}")
                return False
    elif os.path.exists(chroma_dir):
        st.sidebar.success("âœ… Base de conocimiento disponible")
        return True
    else:
        st.sidebar.info("â„¹ï¸ Sin base de conocimiento pre-cargada")
        return False

# Descomprimir al inicio (antes de cualquier otra operaciÃ³n)
CHROMA_AVAILABLE = ensure_chroma_db()

@st.cache_resource
def load_vectorstore():
    """Carga el vectorstore ChromaDB si estÃ¡ disponible"""
    if not CHROMA_AVAILABLE:
        return None
    
    try:
        from langchain_huggingface import HuggingFaceEmbeddings
        from langchain_community.vectorstores import Chroma
        
        embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-small-en-v1.5",
            model_kwargs={"device": "cpu"},
            encode_kwargs={"normalize_embeddings": True}
        )
        
        vectorstore = Chroma(
            persist_directory="chroma_db",
            embedding_function=embeddings
        )
        
        return vectorstore
        
    except Exception as e:
        st.sidebar.warning(f"âš ï¸ Error cargando vectorstore: {str(e)[:100]}")
        return None

# Cargar vectorstore (cacheado)
vectorstore = load_vectorstore()

def retrieve_context(query, top_k=3):
    """Recupera contexto relevante del vectorstore + documento subido"""
    contexts = []
    sources = set()
    
    # 1. Recuperar de vectorstore ChromaDB (RAG)
    if vectorstore:
        try:
            docs = vectorstore.similarity_search(query, k=top_k)
            if docs:
                rag_context = "\n\n".join([
                    f"[{i+1}] {doc.page_content}" 
                    for i, doc in enumerate(docs)
                ])
                contexts.append(f"Documentos de referencia:\n{rag_context}")
                sources.update([
                    doc.metadata.get("source", "Desconocido") 
                    for doc in docs
                ])
        except Exception as e:
            st.sidebar.warning(f"âš ï¸ Error en bÃºsqueda semÃ¡ntica: {str(e)[:50]}")
    
    # 2. Agregar documento subido por usuario
    if st.session_state.document_text:
        contexts.append(
            f"Documento actual ({st.session_state.document_name}):\n"
            f"{st.session_state.document_text}"
        )
        sources.add(st.session_state.document_name)
    
    # Combinar contextos
    full_context = "\n\n---\n\n".join(contexts) if contexts else "No hay documentos disponibles."
    return full_context, sources

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIÃ“N DE API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
IS_CLOUD = os.getenv("HOME") == "/home/appuser"

if IS_CLOUD:
    if "OPENAI_API_KEY" not in st.secrets:
        st.error("âŒ ERROR: Configura OPENAI_API_KEY en Settings â†’ Secrets")
        st.stop()
    api_key = st.secrets["OPENAI_API_KEY"]
    api_base = st.secrets.get("OPENAI_API_BASE", "https://openrouter.ai/api/v1").strip()
else:
    api_key = os.getenv("OPENAI_API_KEY", "demo-key")
    api_base = "https://openrouter.ai/api#/v1"

client = OpenAI(api_key=api_key, base_url=api_base)

# âœ… MODELO VMODEL= "deepseek/deepseek-v3.2"ÃLIDO Y GRATUITO EN OPENROUTER (NO deepseek-v3.2)
MODEL = "mistralai/mistral-7b-instruct:free"  # âœ… 100% gratuito, sin costo

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTERFAZ DE USUARIO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
st.set_page_config(page_title="ChatAcredita", page_icon="ğŸ“", layout="wide")

# Cabecera con texto institucional (logos opcionales)
col_logo1, col_title, col_logo2 = st.columns([1, 2, 1])

with col_logo1:
    st.markdown("### ğŸ“ EISC")

with col_title:
    st.markdown(
        "<h1 style='text-align:center;color:#c00000;margin:0;'>ğŸ¤– ChatAcredita</h1>",
        unsafe_allow_html=True
    )
    st.markdown(
        "<h3 style='text-align:center;color:#1a5276;margin:0 0 10px 0;'>"
        "Asistente de AcreditaciÃ³n - EISC Univalle</h3>",
        unsafe_allow_html=True
    )

with col_logo2:
    st.markdown("### ğŸ›ï¸ Univalle")

st.markdown('<hr style="border: 2px solid #c00000; margin: 10px 0;">', unsafe_allow_html=True)

# Panel lateral informativo
with st.sidebar:
    st.markdown("### ğŸ“š InformaciÃ³n")
    st.markdown("""
    **ChatAcredita** es un asistente especializado en procesos de acreditaciÃ³n de programas de la Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n.
    
    ### ğŸ“¥ CÃ³mo usar:
    1. Sube un documento PDF relacionado con acreditaciÃ³n
    2. Escribe tu pregunta en el chat
    3. ObtÃ©n respuestas basadas en documentos oficiales + tu PDF
    
    ### ğŸ’¡ Consejo:
    Para mejores resultados, sube documentos oficiales como:
    - GuÃ­as de acreditaciÃ³n de la EISC
    - Resoluciones del CNA
    - EstÃ¡ndares de calidad institucionales
    """)
    
    if vectorstore:
        st.markdown("### âœ… RAG Activo")
        st.markdown("ğŸ” BÃºsqueda semÃ¡ntica disponible")
    else:
        st.markdown("### âš ï¸ RAG No disponible")
        st.markdown("Sube chroma_db.zip a tu repositorio GitHub")

# Subida de documento
uploaded = st.file_uploader("ğŸ“„ Sube un PDF sobre acreditaciÃ³n", type=["pdf"])

if uploaded:
    try:
        import fitz
        doc = fitz.open(stream=uploaded.read(), filetype="pdf")
        text = ""
        for page in doc:
            text += page.get_text()
        doc.close()
        st.session_state.document_text = text[:5000]
        st.session_state.document_name = uploaded.name
        st.success(f"âœ… PDF procesado: {st.session_state.document_name}")
    except Exception as e:
        st.error(f"âŒ Error al procesar PDF: {str(e)[:100]}")

# Mostrar historial de chat
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input del usuario
if prompt := st.chat_input("Escribe tu pregunta sobre acreditaciÃ³n..."):
    # Guardar mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # Generar respuesta
    with st.chat_message("assistant"):
        placeholder = st.empty()
        placeholder.markdown("ğŸ§  Buscando informaciÃ³n relevante...")
        
        # âœ… RECUPERACIÃ“N RAG (clave del sistema)
        full_context, sources = retrieve_context(prompt, top_k=3)
        
        # Mostrar fuentes utilizadas
        if sources:
            sources_text = " | ".join([s for s in sources if s != "Desconocido"])
            placeholder.markdown(f"ğŸ“š Fuentes: {sources_text}\n\nGenerando respuesta...")
        else:
            placeholder.markdown("Generando respuesta...")
        
        # Generar respuesta con LLM
        try:
            stream = client.chat.completions.create(
                model=MODEL,
                messages=[
                    {
                        "role": "system", 
                        "content": (
                            "Eres ChatAcredita, asistente especializado en acreditaciÃ³n de programas de la "
                            "Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n de la Universidad del Valle. "
                            "Responde SOLO con base en el contexto proporcionado. SÃ© preciso, conciso y profesional. "
                            "Si no hay informaciÃ³n suficiente en el contexto, indÃ­calo honestamente."
                        )
                    },
                    {
                        "role": "user", 
                        "content": f"Contexto:\n{full_context}\n\nPregunta: {prompt}\n\nRespuesta:"
                    }
                ],
                max_tokens=500,
                temperature=0.3,
                stream=True
            )
            
            # Mostrar respuesta en streaming
            answer = ""
            for chunk in stream:
                if chunk.choices[0].delta.content:
                    answer += chunk.choices[0].delta.content
                    placeholder.markdown(answer + "â–Œ")
            
            # Mostrar respuesta final
            placeholder.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})
            
        except Exception as e:
            error_msg = f"âŒ Error: {str(e)[:150]}"
            placeholder.markdown(error_msg)
            st.session_state.messages.append({"role": "assistant", "content": error_msg})
            
            # DiagnÃ³stico especÃ­fico para errores comunes
            error_str = str(e).lower()
            if "400" in error_str and "not a valid model" in error_str:
                st.error("""
                ğŸ”‘ **SoluciÃ³n:** El modelo especificado no existe en OpenRouter.
                Usa 'mistralai/mistral-7b-instruct:free' (gratuito) o consulta:
                https://openrouter.ai/models
                """)
            elif "401" in error_str or "authentication" in error_str:
                st.error("""
                ğŸ”‘ **SoluciÃ³n:** API key invÃ¡lida o sin crÃ©ditos.
                1. Regenera tu key en https://openrouter.ai/keys
                2. Configura Secrets en Streamlit Cloud
                """)

# Mensaje de bienvenida si no hay historial
if len(st.session_state.messages) == 0:
    with st.chat_message("assistant"):
        st.markdown("""
        ğŸ‘‹ Â¡Hola! Soy **ChatAcredita**, tu asistente especializado en procesos de acreditaciÃ³n de programas de la **Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n**.
        
        ### ğŸš€ Para empezar:
        1. **Sube un documento** relacionado con acreditaciÃ³n usando el botÃ³n de arriba
        2. **Haz tu pregunta** en el campo de chat
        3. **ObtÃ©n respuestas** basadas en documentos oficiales + tu documento
        
        ### ğŸ’¡ Ejemplos de preguntas Ãºtiles:
        - "Â¿CuÃ¡les son los requisitos para acreditar un programa de pregrado?"
        - "Â¿QuÃ© estÃ¡ndares de calidad se evalÃºan en la acreditaciÃ³n?"
        - "Â¿CuÃ¡l es el proceso de autoevaluaciÃ³n institucional?"
        
        *Nota: Mis respuestas se basan en documentos oficiales de acreditaciÃ³n y el documento que me proporciones.*
        """)

# Footer
st.markdown("---")
st.markdown(
    "<div style='text-align:center;color:#7f8c8d;font-size:0.9em;padding:10px 0;'>"
    "Desarrollado por <strong>GUIA</strong> - Grupo de Univalle en Inteligencia Artificial | "
    "Escuela de IngenierÃ­a de Sistemas y ComputaciÃ³n | Universidad del Valle"
    "</div>",
    unsafe_allow_html=True
)